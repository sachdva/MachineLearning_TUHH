---
title: "04 Performance Measures"
date: "2020-21-05"
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    collapsed: false
    number_sections: true
    toc_depth: 3
    #code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```


Leaderboard visualization
Tune a model with grid search
Visualize the trade of between the precision and the recall and the optimal threshold
ROC Plot
Precision vs Recall Plot
Gain Plot
Lift Plot
Dashboard with cowplot

```{r}
# Load data
library(tidyverse)
library(readxl)
library(skimr)
library(GGally)
library(h2o)
library(rsample)
library(recipes)
library(cowplot)
library(glue)


# Load the training & test dataset
p_bko <- read_csv("raw_data/pdbk.csv")

# Split into test and train
set.seed(seed = 1113)
split_obj <- rsample::initial_split(p_bko, prop = 0.85)

# Assign training and test data
train_data <- training(split_obj)
test_data <- testing(split_obj)


factor_names <-  c("went_on_backorder")

recipe_obj <- 
  recipe(went_on_backorder ~ ., data = train_data) %>%  
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  step_zv(all_predictors()) %>% 
  step_mutate_at(factor_names, fn = as.factor) %>%
  # prepare the final recipe
  
  prep()

train_tbl <- bake(recipe_obj, new_data = train_data)
test_tbl  <- bake(recipe_obj, new_data = test_data)


# Modeling
h2o.init()

# Split data into a training and a validation data frame
# Setting the seed is just for reproducability
split_h2o <- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)
train_h2o <- split_h2o[[1]]
valid_h2o <- split_h2o[[2]]
test_h2o  <- as.h2o(test_tbl)

# Set the target and predictors
y <- "went_on_backorder"
x <- setdiff(names(train_h2o), y)


 automl_models_h2o <- h2o.automl(
   x = x,
  y = y,
  training_frame    = train_h2o,
  validation_frame  = valid_h2o,
  leaderboard_frame = test_h2o,
  max_runtime_secs  = 120,
  nfolds            = 5
)

typeof(automl_models_h2o)
slotNames(automl_models_h2o)
automl_models_h2o@leaderboard
automl_models_h2o@leader


# automl_models_h2o@leaderboard %>% 
#               as_tibble() %>% 
#               select(-c(mean_per_class_error, rmse, mse))


# Visualize the H2O leaderboard to help with model selection
data_transformed_tbl <- automl_models_h2o@leaderboard %>%
        as_tibble() %>%
        select(-c(aucpr, mean_per_class_error, rmse, mse)) %>% 
        mutate(model_type = str_extract(model_id, "[^_]+")) %>%
        # slice(1:15) %>% 
        rownames_to_column(var = "rowname") %>%
        # Visually this step will not change anything
        # It reorders the factors under the hood
        mutate(
          model_id   = as_factor(model_id) %>% reorder(auc),
          model_type = as.factor(model_type)
          ) %>% 
          pivot_longer(cols = -c(model_id, model_type, rowname), 
                       names_to = "key", 
                       values_to = "value", 
                       names_transform = list(key = forcats::fct_inorder)
                       ) %>% 
        mutate(model_id = paste0(rowname, ". ", model_id) %>% as_factor() %>% fct_rev())

data_transformed_tbl %>%
        ggplot(aes(value, model_id, color = model_type)) +
        geom_point(size = 3) +
        geom_label(aes(label = round(value, 2), hjust = "inward")) +
        
        # Facet to break out logloss and auc
        facet_wrap(~ key, scales = "free_x") +
        labs(title = "Leaderboard Metrics",
             subtitle = paste0("Ordered by: ", "auc"),
             y = "Model Postion, Model ID", x = "") + 
        theme(legend.position = "bottom")



# plot_h2o_leaderboard <- function(h2o_leaderboard, order_by = c("auc", "logloss"), 
#                                  n_max = 20, size = 4, include_lbl = TRUE) {
# 
#     # Setup inputs
#     # adjust input so that all formats are working
#     order_by <- tolower(order_by[[1]])
# 
#     leaderboard_tbl <- h2o_leaderboard %>%
#         as.tibble() %>%
#         select(-c(aucpr, mean_per_class_error, rmse, mse)) %>% 
#         mutate(model_type = str_extract(model_id, "[^_]+")) %>%
#         rownames_to_column(var = "rowname") %>%
#         mutate(model_id = paste0(rowname, ". ", model_id) %>% as.factor())
# 
#     # Transformation
#     if (order_by == "auc") {
# 
#         data_transformed_tbl <- leaderboard_tbl %>%
#             slice(1:n_max) %>%
#             mutate(
#                 model_id   = as_factor(model_id) %>% reorder(auc),
#                 model_type = as.factor(model_type)
#             ) %>%
#                 pivot_longer(cols = -c(model_id, model_type, rowname), 
#                        names_to = "key", 
#                        values_to = "value", 
#                        names_transform = list(key = forcats::fct_inorder)
#                        )
# 
#     } else if (order_by == "logloss") {
# 
#         data_transformed_tbl <- leaderboard_tbl %>%
#             slice(1:n_max) %>%
#             mutate(
#                 model_id   = as_factor(model_id) %>% reorder(logloss) %>% fct_rev(),
#                 model_type = as.factor(model_type)
#             ) %>%
#             pivot_longer(cols = -c(model_id, model_type, rowname), 
#                        names_to = "key", 
#                        values_to = "value", 
#                        names_transform = list(key = forcats::fct_inorder)
#                        )
# 
#     } else {
#         # If nothing is supplied
#         stop(paste0("order_by = '", order_by, "' is not a permitted option."))
#     }
# 
#     # Visualization
#     g <- data_transformed_tbl %>%
#         ggplot(aes(value, model_id, color = model_type)) +
#         geom_point(size = size) +
#         facet_wrap(~ key, scales = "free_x") +
#         labs(title = "Leaderboard Metrics",
#              subtitle = paste0("Ordered by: ", toupper(order_by)),
#              y = "Model Postion, Model ID", x = "")
# 
#     if (include_lbl) g <- g + geom_label(aes(label = round(value, 2), 
#                                              hjust = "inward"))
# 
#     return(g)
# 
# }
automl_models_h2o@leaderboard


#picking the second best for me 
# h2o.getModel("GBM_grid__1_AutoML_20210523_102817_model_1") %>%
#   h2o.saveModel(path = "04_Modeling/h20_models/")
deeplearning_h2o <- h2o.loadModel("04_Modeling/h20_models/GBM_grid__1_AutoML_20210523_102817_model_1")

# Take a look for the metrics on the training data set
# For my model the total error in the confusion matrix is ~7 %
deeplearning_h2o

# We want to see how it performs for the testing data frame
test_tbl

# Make sure to convert it to an h20 object
# Accuracy of the confusion matrix shows ~94 % accuracy
h2o.performance(deeplearning_h2o, newdata = as.h2o(test_tbl))

deeplearning_grid_01 <- h2o.grid(

    # See help page for available algos
    algorithm = "deeplearning",
    
    # I just use the same as the object
    grid_id = "deeplearning_grid_01",
    
    # The following is for ?h2o.deeplearning()
    # predictor and response variables
    x = x,
    y = y,
    
    # training and validation frame and crossfold validation
    training_frame   = train_h2o,
    validation_frame = valid_h2o,
    nfolds = 5,
    
    # Hyperparamters: Use deeplearning_h2o@allparameters to see all
    hyper_params = list(
        # Use some combinations (the first one was the original)
        hidden = list(c(10, 10, 10), c(50, 20, 10), c(20, 20, 20)),
        epochs = c(10, 50, 100)
    )
)

deeplearning_grid_01
h2o.getGrid(grid_id = "deeplearning_grid_01", sort_by = "auc", decreasing = TRUE)
deeplearning_grid_01_model_1 <- h2o.getModel("deeplearning_grid_01_model_1")

deeplearning_grid_01_model_1 %>% h2o.auc(train = T, valid = T, xval = T)
# We can tell the model is overfitting because of the huge difference between training AUC and the validation / cross validation AUC

# Run it on the test data
deeplearning_grid_01_model_1 %>%
    h2o.performance(newdata = as.h2o(test_tbl))


# 4. Assessing Performance ----
automl_models_h2o@leaderboard

# h2o.getModel("StackedEnsemble_AllModels_AutoML_20210523_102817") %>%
#   h2o.saveModel(path = "04_Modeling/h20_models/")
# h2o.getModel("GBM_grid__1_AutoML_20210523_102817_model_1") %>%
#   h2o.saveModel(path = "04_Modeling/h20_models/")
# h2o.getModel("GBM_1_AutoML_20210523_102817") %>%
#   h2o.saveModel(path = "04_Modeling/h20_models/")

stacked_ensemble_h2o <- h2o.loadModel("04_Modeling/h20_models/StackedEnsemble_AllModels_AutoML_20210523_102817") #best
deeplearning_h2o     <- h2o.loadModel("04_Modeling/h20_models/GBM_grid__1_AutoML_20210523_102817_model_1 ") #2nd best
glm_h2o              <- h2o.loadModel("04_Modeling/h20_models/GBM_1_AutoML_20210523_102817 ") #8th best 
#misleading variable names as they are not these specific models


performance_h2o <- h2o.performance(stacked_ensemble_h2o, newdata = as.h2o(test_tbl))

typeof(performance_h2o)
performance_h2o %>% slotNames()

# We are focusing on the slot metrics. This slot contains all possible metrics
performance_h2o@metrics

# Classifier Summary Metrics

h2o.auc(performance_h2o, train = T, valid = T, xval = T)
h2o.auc(stacked_ensemble_h2o, train = T, valid = T, xval = T)
h2o.giniCoef(performance_h2o)
h2o.logloss(performance_h2o)
# result for the training data
h2o.confusionMatrix(stacked_ensemble_h2o)
# result for the hold out set
h2o.confusionMatrix(performance_h2o)



# Precision vs Recall Plot

# This is on the test set
performance_tbl <- performance_h2o %>%
    h2o.metric() %>%
    as.tibble() 

performance_tbl %>% 
  glimpse()


theme_new <- theme(
      legend.position  = "bottom",
      legend.key       = element_blank(),
      panel.background = element_rect(fill   = "transparent"),
      panel.border     = element_rect(color = "black", fill = NA, size = 0.5),
      panel.grid.major = element_line(color = "grey", size = 0.333)
      ) 

performance_tbl %>%
    filter(f1 == max(f1))

performance_tbl %>%
    ggplot(aes(x = threshold)) +
    geom_line(aes(y = precision), color = "blue", size = 1) +
    geom_line(aes(y = recall), color = "red", size = 1) +
    
    # Insert line where precision and recall are harmonically optimized
    geom_vline(xintercept = h2o.find_threshold_by_max_metric(performance_h2o, "f1")) +
    labs(title = "Precision vs Recall", y = "value") +
    theme_new


# ROC Plot

path <- "04_Modeling/h20_models/StackedEnsemble_AllModels_AutoML_20210523_102817"

load_model_performance_metrics <- function(path, test_tbl) {
    
    model_h2o <- h2o.loadModel(path)
    perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) 
    
    perf_h2o %>%
        h2o.metric() %>%
        as_tibble() %>%
        mutate(auc = h2o.auc(perf_h2o)) %>%
        select(tpr, fpr, auc)
    
}

model_metrics_tbl <- fs::dir_info(path = "04_Modeling/h20_models/") %>%
    select(path) %>%
    mutate(metrics = map(path, load_model_performance_metrics, test_tbl)) %>%
    unnest(cols = metrics)


model_metrics_tbl %>%
    mutate(
        # Extract the model names
        path = str_split(path, pattern = "/", simplify = T)[,3] %>% as_factor(),
        auc  = auc %>% round(3) %>% as.character() %>% as_factor()
        ) %>%
    ggplot(aes(fpr, tpr, color = path, linetype = auc)) +
    geom_line(size = 1) +
    
    # just for demonstration purposes
    geom_abline(color = "red", linetype = "dotted") +
    
    theme_new +
    theme(
      legend.direction = "vertical",
      ) +
    labs(
        title = "ROC Plot",
        subtitle = "Performance of Models in Directory"
    )



# Precision vs Recall

load_model_performance_metrics <- function(path, test_tbl) {
    
    model_h2o <- h2o.loadModel(path)
    perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) 
    
    perf_h2o %>%
        h2o.metric() %>%
        as_tibble() %>%
        mutate(auc = h2o.auc(perf_h2o)) %>%
        select(tpr, fpr, auc, precision, recall)
    
}

model_metrics_tbl <- fs::dir_info(path = "04_Modeling/h20_models/") %>%
    select(path) %>%
    mutate(metrics = map(path, load_model_performance_metrics, test_tbl)) %>%
    unnest(cols = metrics)

model_metrics_tbl %>%
    mutate(
        path = str_split(path, pattern = "/", simplify = T)[,3] %>% as_factor(),
        auc  = auc %>% round(3) %>% as.character() %>% as_factor()
    ) %>%
    ggplot(aes(recall, precision, color = path, linetype = auc)) +
    geom_line(size = 1) +
    theme_new + 
    theme(
      legend.direction = "vertical",
      ) +
    labs(
        title = "Precision vs Recall Plot",
        subtitle = "Performance of Models in Directory"
    )

predictions <- h2o.predict(stacked_ensemble_h2o, newdata = as.h2o(test_tbl))
predictions_tbl <- predictions %>% as_tibble()

# Gain & Lift

ranked_predictions_tbl <- predictions_tbl %>%
    bind_cols(test_tbl) %>%
    select(predict:Yes, went_on_backorder) %>%
    # Sorting from highest to lowest class probability
    arrange(desc(Yes))



ranked_predictions_tbl %>%
    mutate(ntile = ntile(Yes, n = 10)) %>%
    group_by(ntile) %>%
    summarise(
        cases = n(),
        responses = sum(went_on_backorder == "Yes")
    ) %>%
    arrange(desc(ntile))


calculated_gain_lift_tbl <- ranked_predictions_tbl %>%
    mutate(ntile = ntile(Yes, n = 10)) %>%
    group_by(ntile) %>%
    summarise(
        cases = n(),
        responses = sum(went_on_backorder == "Yes")
    ) %>%
    arrange(desc(ntile)) %>%
    
    # Add group numbers (opposite of ntile)
    mutate(group = row_number()) %>%
    select(group, cases, responses) %>%
    
    # Calculations
    mutate(
        cumulative_responses = cumsum(responses),
        pct_responses        = responses / sum(responses),
        gain                 = cumsum(pct_responses),
        cumulative_pct_cases = cumsum(cases) / sum(cases),
        lift                 = gain / cumulative_pct_cases,
        gain_baseline        = cumulative_pct_cases,
        lift_baseline        = gain_baseline / cumulative_pct_cases
    )

calculated_gain_lift_tbl 

gain_lift_tbl <- performance_h2o %>%
    h2o.gainsLift() %>%
    as.tibble()

## Gain Chart

gain_transformed_tbl <- gain_lift_tbl %>% 
    select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%
    select(-contains("lift")) %>%
    mutate(baseline = cumulative_data_fraction) %>%
    rename(gain     = cumulative_capture_rate) %>%
    # prepare the data for the plotting (for the color and group aesthetics)
    pivot_longer(cols = c(gain, baseline), values_to = "value", names_to = "key")

gain_transformed_tbl %>%
    ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +
    geom_line(size = 1.5) +
    labs(
        title = "Gain Chart",
        x = "Cumulative Data Fraction",
        y = "Gain"
    ) +
    theme_new


## Lift Plot

lift_transformed_tbl <- gain_lift_tbl %>% 
    select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%
    select(-contains("capture")) %>%
    mutate(baseline = 1) %>%
    rename(lift = cumulative_lift) %>%
    pivot_longer(cols = c(lift, baseline), values_to = "value", names_to = "key")

lift_transformed_tbl %>%
    ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +
    geom_line(size = 1.5) +
    labs(
        title = "Lift Chart",
        x = "Cumulative Data Fraction",
        y = "Lift"
    ) +
    theme_new

# 5. Performance Visualization ----  

# set values to test the function while building it
h2o_leaderboard <- automl_models_h2o@leaderboard
newdata <- test_tbl
order_by <- "auc"
max_models <- 4
size <- 1

plot_h2o_performance <- function(h2o_leaderboard, newdata, order_by = c("auc", "logloss"),
                                 max_models = 3, size = 1.5) {
    
    # Inputs
    
    leaderboard_tbl <- h2o_leaderboard %>%
        as_tibble() %>%
        dplyr::slice(1:max_models)
    
    newdata_tbl <- newdata %>%
        as_tibble()
    
    # Selecting the first, if nothing is provided
    order_by      <- tolower(order_by[[1]]) 
    
    # Convert string stored in a variable to column name (symbol)
    order_by_expr <- rlang::sym(order_by)

    # Turn of the progress bars ( opposite h2o.show_progress())
    h2o.no_progress()
    
    # 1. Model metrics
    
    get_model_performance_metrics <- function(model_id, test_tbl) {
        
        model_h2o <- h2o.getModel(model_id)
        perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl))
        
        perf_h2o %>%
            h2o.metric() %>%
            as.tibble() %>%
            select(threshold, tpr, fpr, precision, recall)
        
    }
    
    model_metrics_tbl <- leaderboard_tbl %>%
        mutate(metrics = map(model_id, get_model_performance_metrics, newdata_tbl)) %>%
        unnest(cols = metrics) %>%
        mutate(
          model_id = as_factor(model_id) %>% 
                      # programmatically reorder factors depending on order_by
                      fct_reorder(!! order_by_expr, 
                                  .desc = ifelse(order_by == "auc", TRUE, FALSE)),
          auc      = auc %>% 
                      round(3) %>% 
                      as.character() %>% 
                      as_factor() %>% 
                      fct_reorder(as.numeric(model_id)),
          logloss  = logloss %>% 
                      round(4) %>% 
                      as.character() %>% 
                      as_factor() %>% 
                      fct_reorder(as.numeric(model_id))
        )
    
    
    # 1A. ROC Plot
    
    p1 <- model_metrics_tbl %>%
        ggplot(aes(fpr, tpr, color = model_id, linetype = !! order_by_expr)) +
        geom_line(size = size) +
        theme_new +
        labs(title = "ROC", x = "FPR", y = "TPR") +
        theme(legend.direction = "vertical") 
        
    
    # 1B. Precision vs Recall
    
    p2 <- model_metrics_tbl %>%
        ggplot(aes(recall, precision, color = model_id, linetype = !! order_by_expr)) +
        geom_line(size = size) +
        theme_new +
        labs(title = "Precision Vs Recall", x = "Recall", y = "Precision") +
        theme(legend.position = "none") 
    
    
    # 2. Gain / Lift
    
    get_gain_lift <- function(model_id, test_tbl) {
        
        model_h2o <- h2o.getModel(model_id)
        perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) 
        
        perf_h2o %>%
            h2o.gainsLift() %>%
            as.tibble() %>%
            select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift)
        
    }
    
    gain_lift_tbl <- leaderboard_tbl %>%
        mutate(metrics = map(model_id, get_gain_lift, newdata_tbl)) %>%
        unnest(cols = metrics) %>%
        mutate(
            model_id = as_factor(model_id) %>% 
                fct_reorder(!! order_by_expr, 
                            .desc = ifelse(order_by == "auc", TRUE, FALSE)),
            auc  = auc %>% 
                round(3) %>% 
                as.character() %>% 
                as_factor() %>% 
                fct_reorder(as.numeric(model_id)),
            logloss = logloss %>% 
                round(4) %>% 
                as.character() %>% 
                as_factor() %>% 
                fct_reorder(as.numeric(model_id))
        ) %>%
        rename(
            gain = cumulative_capture_rate,
            lift = cumulative_lift
        ) 
    
    # 2A. Gain Plot
    
    p3 <- gain_lift_tbl %>%
        ggplot(aes(cumulative_data_fraction, gain, 
                          color = model_id, linetype = !! order_by_expr)) +
        geom_line(size = size,) +
        geom_segment(x = 0, y = 0, xend = 1, yend = 1, 
                     color = "red", size = size, linetype = "dotted") +
        theme_new +
        expand_limits(x = c(0, 1), y = c(0, 1)) +
        labs(title = "Gain",
             x = "Cumulative Data Fraction", y = "Gain") +
        theme(legend.position = "none")
    
    # 2B. Lift Plot
    
    p4 <- gain_lift_tbl %>%
        ggplot(aes(cumulative_data_fraction, lift, 
                          color = model_id, linetype = !! order_by_expr)) +
        geom_line(size = size) +
        geom_segment(x = 0, y = 1, xend = 1, yend = 1, 
                     color = "red", size = size, linetype = "dotted") +
        theme_new +
        expand_limits(x = c(0, 1), y = c(0, 1)) +
        labs(title = "Lift",
             x = "Cumulative Data Fraction", y = "Lift") +
        theme(legend.position = "none") 
    
    
    # Combine using cowplot
    
    # cowplot::get_legend extracts a legend from a ggplot object
    p_legend <- get_legend(p1)
    # Remove legend from p1
    p1 <- p1 + theme(legend.position = "none")
    
    # cowplot::plt_grid() combines multiple ggplots into a single cowplot object
    p <- cowplot::plot_grid(p1, p2, p3, p4, ncol = 2)
    
    # cowplot::ggdraw() sets up a drawing layer
    p_title <- ggdraw() + 
    
        # cowplot::draw_label() draws text on a ggdraw layer / ggplot object
        draw_label("H2O Model Metrics", size = 18, fontface = "bold", 
                   color = "#2C3E50")
    
    p_subtitle <- ggdraw() + 
        draw_label(glue("Ordered by {toupper(order_by)}"), size = 10,  
                   color = "#2C3E50")
    
    # Combine everything
    ret <- plot_grid(p_title, p_subtitle, p, p_legend, 
    
                     # Adjust the relative spacing, so that the legends always fits
                     ncol = 1, rel_heights = c(0.05, 0.05, 1, 0.05 * max_models))
    
    h2o.show_progress()
    
    return(ret)
    
}

automl_models_h2o@leaderboard %>%
    plot_h2o_performance(newdata = test_tbl, order_by = "logloss", 
                         size = 0.5, max_models = 4)
```
